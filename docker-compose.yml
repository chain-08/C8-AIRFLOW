services:
  postgres:
    image: postgres:14.7
    container_name: postgres-airflow
    restart: always
    environment:
      POSTGRES_USER: airflow
      POSTGRES_DB: airflow
      POSTGRES_PASSWORD_FILE: /run/secrets/postgres_password
    secrets:
      - postgres_password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - c8_crons
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 10s
      retries: 5
      start_period: 20s
      timeout: 10s

  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile
    image: apache/airflow:2.7.3-python3.10
    container_name: airflow-webserver
    restart: always
    depends_on:
      postgres:
        condition: service_healthy
    env_file:
      - .env
    ports:
      - "8080:8080"
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY:-your_fernet_key_here}
      AIRFLOW__API__AUTH_BACKENDS: airflow.api.auth.backend.basic_auth
    volumes:
      - ./entrypoint.sh:/opt/airflow/entrypoint.sh
      - ./dags:/opt/airflow/dags
      - /media/inglorious/ds/logs/airflow:/opt/airflow/logs
      - /media/inglorious/ds/logs/plugins:/opt/airflow/plugins
    networks:
      - c8_crons
    entrypoint: /opt/airflow/entrypoint.sh
    command: ["airflow", "webserver"]
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8080/health || exit 1"]
      interval: 30s
      retries: 5
      start_period: 20s
      timeout: 10s

  airflow-scheduler:
    image: apache/airflow:2.7.3-python3.10
    container_name: airflow-scheduler
    restart: always
    depends_on:
      postgres:
        condition: service_healthy
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY:-your_fernet_key_here}
      AIRFLOW__API__AUTH_BACKENDS: airflow.api.auth.backend.basic_auth
    volumes:
      - ./entrypoint.sh:/opt/airflow/entrypoint.sh
      - ./dags:/opt/airflow/dags
      - /media/inglorious/ds/logs/airflow:/opt/airflow/logs
      - /media/inglorious/ds/logs/plugins:/opt/airflow/plugins
    networks:
      - c8_crons
    entrypoint: /opt/airflow/entrypoint.sh
    command: ["airflow", "scheduler"]

  kafka:
    image: confluentinc/cp-kafka:7.9.1
    container_name: kafka-server
    restart: always
    hostname: kafka-server
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      KAFKA_KRAFT_MODE: "true"
      KAFKA_PROCESS_ROLES: "controller,broker"
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka-server:9093"
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka-server:9092"
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      CLUSTER_ID: "jX3k8fxjRX-b7I9OgYPLQg"
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - c8_crons
    healthcheck:
      test: ["CMD-SHELL", "echo > /dev/tcp/kafka-server/9092 || exit 1"]
      interval: 30s
      retries: 5
      start_period: 40s
      timeout: 10s

  atlas-observer:
    container_name: atlas-observer
    image: atlas-observer:dev
    build:
      context: ../c8-atlas            # repo root so pyproject.toml and src/ are in context
      dockerfile: docker/Dockerfile   # the Dockerfile we created above
    environment:
      AIRFLOW_BASE_URL: http://airflow-webserver:8080
      AIRFLOW_USERNAME: ${AIRFLOW_USERNAME}
      AIRFLOW_PASSWORD: ${AIRFLOW_PASSWORD}
      SLACK_BOT_TOKEN: ${SLACK_BOT_TOKEN}
      SLACK_CHANNEL_DIGEST: ${SLACK_CHANNEL_DIGEST:-#atlas-digest}
      ATLAS_ENV: ${ATLAS_ENV:-dev}
      POLL_INTERVAL_SEC: ${POLL_INTERVAL_SEC:-120}
      DIGEST_CRON_IST: ${DIGEST_CRON_IST:-"15 9 * * *"}
    depends_on:
    - airflow-webserver
    ports:
    - "8087:8087"
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:8087/healthz || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 5
    networks:
      - c8_crons

networks:
  c8_crons:
    driver: bridge

volumes:
  kafka_data:
  postgres_data:

secrets:
  postgres_password:
    file: ./secrets/postgres_password.txt
